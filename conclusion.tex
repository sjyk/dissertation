\chapter{Conclusions}
This dissertation started with the challenge that \emph{Deep RL conflates statistical learning with sequential search.} Conflating these very different optimization algorithms leads to a chicken-and-egg problem where one of the problems must be solved before the other can make progress. My thesis is that \emph{it is possible to learn important structural features of a sequential prediction task from a limited ammount of expert data to significantly improve the sample-efficiency, stability, and applicability of Deep RL.} 
With this additional supervision, the search process can be restricted to those sequences that are similar to the supervision provided by the expert.
My work over the last 6 years explores this architecture in several Deep RL systems for control of imprecise cable-driven surgical robots, automatically synthesizing data-cleaning programs to meet quality specifications, and generating efficient execution plans for relational queries. I describe algorithmic contributions, theoretical analysis about the implementations themselves, and the architecture of the RL systems.

\section{Challenges and Open Problems}
\textbf{TODO}